{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMOST imaging and processing\n",
    "\n",
    "As part of the [BRAIN Initiative Cell Census Network (BICCN)](https://biccn.org/) efforts to characterize brain cell types across multiple modalities, [Peng et al 2021](https://www.nature.com/articles/s41586-021-03941-1), established a pipeline to label, image, reconstruct and classify single neurons in mice.\n",
    "\n",
    "These neurons are labelled by cell subclass or type-selective Cre driver lines, enabling correlation of their morphologies and projection patterns with molecular identities. \n",
    "\n",
    "A GFP-labelled brain is first embedded in resin for imaging in the fMOST platform. Following imaging of the entire block face, the top 1 µm of tissue is sliced off with a diamond knife, exposing the next face of the block for imaging. For the entire mouse brain, a 15–20 TB dataset containing about 10,000 coronal planes of 0.2–0.3 µm xy resolution and 1 µm z sampling rate is generated within 2 weeks.\n",
    "\n",
    "Vaa3D, an open-source, cross-platform visualization and analysis system, to use for reconstructing neuronal morphologies. Further, mBrainAligner software was used to perform 3D registration from fMOST images (subject) to the average template of the Allen CCFv3 (reference). Axonal and dendritic morphological features and projection patterns were quantified and used to identifed 11 major projection neuron types.\n",
    "\n",
    "The [fMOST imaging data](https://download.brainimagelibrary.org/biccn/zeng/luo/fMOST/) and [1,741 neuronal reconstructions (original and mapped)](https://doi.brainimagelibrary.org/doi/10.35077/g.25) are available for download at the Brain Imaging Library (BIL)\n",
    "\n",
    "[Extended Data Fig.3](https://www.nature.com/articles/s41586-021-03941-1/figures/7): Platform and workflow of the brain-wide complete morphology imaging, reconstruction, registration and analysis pipeline.\n",
    "![Platform and Workflow](ExtendFig3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allen Common Coordinate Framework CCFv3\n",
    "\n",
    "Allen Mouse Brain Common Coordinate Framework (CCFv3, [Wang et al, 2020](https://doi.org/10.1016/j.cell.2020.04.007)) is a 3D reference space by creating an\n",
    "average brain at 10um voxel resolution from serial two-photon tomography images of 1,675 young adult C57Bl6/J mice. Using multimodal reference data, we parcellated the entire brain directly in 3D, labeling every voxel with a brain structure spanning 43 isocortical areas and their layers, 314 subcortical gray matter structures, 81 fiber tracts, and 8 ventricular structures.\n",
    "\n",
    "CCFv is used in informatics pipelines and online applications to analyze, visualize and integrate multimodal and multiscale data sets in 3D, and is openly accessible for research use. CCFv3 is currently been used as the integration framework for the projects such as [Allen Brain Map](https://portal.brain-map.org/), [BICCN](https://biccn.org/), [IBL](https://www.internationalbrainlab.com/) and [eBrains](https://ebrains.eu/). \n",
    "\n",
    "![AllenCCFv3](AllenCCFv3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration Challenge\n",
    "\n",
    "This aim of this hackathon is to generate reproducible pipelines to register whole-brain microscopy image data to the CCFv3. The fMOST dataset described above is particular challenging due to the distortion caused by the fixation and dehydration specimen processing steps.\n",
    "\n",
    "A typical first step in a registraton workflow is to downsample the imaging to preform the initial registration. For the hackathon, we have pre-downsample to 7-10 µm resolution volumes. The downsampled data can be found in this directory:\n",
    "https://download.brainlib.org/hackathon/2022_GYBS/input/fMOST/subject/ which can be downloaded or directly accessed via one of the provided hackathon workstations.\n",
    "\n",
    "The volumes are in [NIfTI](https://nifti.nimh.nih.gov/) file format which is commonly used in neuroimaging and can be opened in Python using software such as [SimpleITK](https://simpleitk.org/) and [NiBabel](https://nipy.org/nibabel/nifti_images.html) or in viewers such as [Slicer](https://www.slicer.org/) and [ITKSNAP](http://www.itksnap.org/pmwiki/pmwiki.php)\n",
    "\n",
    "In the following section, we will demonstrate how to read the reference and one of the subject volume using SimpleITK. Refer to the [SimpleITK documentation](https://simpleitk.readthedocs.io/en/master/gettingStarted.html) for more information of features and usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install notebook dependencies\n",
    "import sys\n",
    "\n",
    "#!{sys.executable} -m pip install SimpleITK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import notebook dependencies\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fMOST/reference/average_template_25_mm_ASL.nii.gz already exists.\n",
      "fMOST/subject/194061_red_mm_SLA.nii.gz already exists.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve data from download.brainlib.org\n",
    "files = ['fMOST/reference/average_template_25_mm_ASL.nii.gz','fMOST/subject/194061_red_mm_SLA.nii.gz']\n",
    "\n",
    "os.makedirs(\"fMOST\", exist_ok=True)\n",
    "os.makedirs(\"fMOST/reference\", exist_ok=True)\n",
    "os.makedirs(\"fMOST/subject\", exist_ok=True)\n",
    "\n",
    "for f in files :\n",
    "    if os.path.exists(f):\n",
    "        print(f\"{f} already exists.\")\n",
    "    else:\n",
    "        download_url = f\"https://download.brainlib.org/hackathon/2022_GYBS/input/{f}\"\n",
    "        print(f\"Downloading {download_url} into {f}\")\n",
    "        response = requests.get(download_url, stream=True)\n",
    "        with open(f, \"wb\") as fp:\n",
    "            response.raw.decode_content = True\n",
    "            shutil.copyfileobj(response.raw, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images from files\n",
    "reference = sitk.ReadImage( files[0] )\n",
    "subject = sitk.ReadImage( files[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print out image information\n",
    "def image_info( img ) :\n",
    "    print('size: ' + str(img.GetSize()) + ' voxels')\n",
    "    print('spacing: ' + str(img.GetSpacing()) + ' mm' )\n",
    "    print('direction: ' + str(img.GetDirection()) )\n",
    "    print('origin: ' + str(img.GetOrigin()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SimpleITK, the orientation is encoded as direction cosine matrix \n",
    "with respect to **RAI** configuration (x: right->left, y: anterior->posterior, z: inferior(ventral)->superior(dorsal).\n",
    "\n",
    "The reference volume:\n",
    "- is 25µm isotropic resolution\n",
    "- has size of 528x320x456 voxels\n",
    "- has orientation  **ASL** (x: anterior->posterior, y: superior->inferior, z: left->right)\n",
    "- has origin located in the RAI corner of the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (528, 320, 456) voxels\n",
      "spacing: (0.02500000037252903, 0.02500000037252903, 0.02500000037252903) mm\n",
      "direction: (-0.0, 0.0, -1.0, 1.0, -0.0, 0.0, 0.0, -1.0, 0.0)\n",
      "origin: (11.375, 0.0, 7.974999904632568)\n"
     ]
    }
   ],
   "source": [
    "# Print out reference volume image information\n",
    "image_info( reference )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subject volume :\n",
    "- is 10µm isotropic resolution\n",
    "- has size of 591x1029x1076) voxels\n",
    "- has orientation **SLA** (x: superior->inferior, y: left->right, z: anterior->posterior)\n",
    "- has origin located in the RAI corner of the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: (591, 1029, 1076) voxels\n",
      "spacing: (0.009999999776482582, 0.009999999776482582, 0.009999999776482582) mm\n",
      "direction: (-0.0, -1.0, 0.0, 0.0, -0.0, 1.0, -1.0, 0.0, 0.0)\n",
      "origin: (10.279999732971191, 0.0, 5.900000095367432)\n"
     ]
    }
   ],
   "source": [
    "# Print out subject volume image information\n",
    "image_info( subject )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "Neuroimaging applications like ITKSNAP and Slicer will use these parameters and reslice and display images slices in world coordinates so that volumes of different orientation and spacing can be visually compared. \n",
    "\n",
    "Comparing the reference (CCFv3) and subject (one fMOST dataset) you can observed that after fixation and dehydration, the specimen is 20% smaller than typical brain and the size of the ventricles appears relatively larger. Additionally, intensity profile between the reference and subject volumes are significantly different with subject volume have much lower anatomical differentiation.\n",
    "\n",
    "![Reference and subject in ITKSNAP](ITKSNAP_axial_reference_subject.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional artifacts includes bright white strips in the background on the left side of the subject brain, as well as regular intensity striping along the horizontal axis.\n",
    "\n",
    "![Coronal slice of subject in ITKSNAP](ITKSNAP_coronal_subject.png)\n",
    "![Sagittal slice of subject in ITKSNAP](ITKSNAP_sagittal_subject.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at mid-sagittal section of the subject volume provides some insight at the type of distortion that has occured and is reminiscent of the configuration of the brain during development.\n",
    "\n",
    "![Midsagittal slice of subject in ITKSNAP](ITKSNAP_midsagittal_reference.png)\n",
    "![Midsagittal slice of subject in ITKSNAP](ITKSNAP_midsagittal_subject.png)\n",
    "![E15.5 reference atlas](DevMouse_reference_atlas.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
